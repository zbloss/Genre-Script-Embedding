{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available:  True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from plotly.offline import iplot, plot, init_notebook_mode\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, Embedding, Dense, LSTM, Flatten\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Conv2D, MaxPooling2D, Dropout, GRU, BatchNormalization\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "print(\"GPU Available: \", tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comedy_dir = '../data/' + 'comedy/'\n",
    "horror_dir = '../data/' + 'horror/'\n",
    "thriller_dir = '../data/' + 'thriller/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Comedy,  Horror, Thriller Scripts into 3 large scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comedy = ''\n",
    "for file in os.listdir(comedy_dir):\n",
    "    \n",
    "    with open(comedy_dir + file) as script:\n",
    "        s = script.read()\n",
    "        comedy += ' ' + s\n",
    "        script.close()\n",
    "        \n",
    "horror = ''\n",
    "for file in os.listdir(horror_dir):\n",
    "    \n",
    "    with open(horror_dir + file) as script:\n",
    "        s = script.read()\n",
    "        horror += ' ' + s\n",
    "        script.close() \n",
    "        \n",
    "thriller = ''\n",
    "for file in os.listdir(thriller_dir):\n",
    "    \n",
    "    with open(thriller_dir + file) as script:\n",
    "        s = script.read()\n",
    "        thriller += ' ' + s\n",
    "        script.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looks like these scripts have character names and other key details in all Caps. \n",
    "\n",
    "## Removing these words to help obscure the text from the film. \n",
    "\n",
    "## Also removing punctuation.\n",
    "\n",
    "## Also Lemmatizing words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(line):\n",
    "    line = re.sub(r'\\b[A-Z]+\\b', '', line)\n",
    "    line = re.sub(r'[^\\w\\s]','', line)\n",
    "    line = re.sub(\" \\d+\", \"\", line)\n",
    "    line = line.lower()\n",
    "    line = ' '.join(line.split())\n",
    "    \n",
    "    lemma_line = []\n",
    "    line = nlp(line)\n",
    "    for word in line:\n",
    "        lemma_line.append(word.lemma_)\n",
    "    \n",
    "    #lemma_line = [l for l in lemma_line]\n",
    "    return ' '.join(lemma_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.max_length = max([len(comedy), len(horror), len(thriller)])\n",
    "\n",
    "comedy = text_cleaner(comedy)\n",
    "horror = text_cleaner(horror)\n",
    "thriller = text_cleaner(thriller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to batch these into multiple dataframes\n",
    "\n",
    "def line_splitter(line, input_len=25):\n",
    "    split_line = line.split()\n",
    "    line_list = []\n",
    "    for i in range(0, len(line), input_len):\n",
    "        line_list.append(split_line[i:i+input_len])\n",
    "        \n",
    "    return line_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "comedy = pd.DataFrame([line_splitter(comedy)]).T\n",
    "horror = pd.DataFrame([line_splitter(horror)]).T\n",
    "thriller = pd.DataFrame([line_splitter(thriller)]).T\n",
    "\n",
    "\n",
    "comedy.columns = horror.columns = thriller.columns = ['line']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_dict = {\n",
    "    0: 'Comedy',\n",
    "    1: 'Horror',\n",
    "    2: 'Thriller'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "comedy['genre'] = 0\n",
    "horror['genre'] = 1\n",
    "thriller['genre'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([comedy, horror, thriller])\n",
    "\n",
    "df = df[df.astype(str)['line'] != '[]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    11519\n",
       "1    10031\n",
       "0     7600\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin to assemble word2idx and idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['line'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "all_text = ' '.join(df['text'].values.tolist())\n",
    "all_test_l = list(set(all_text.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22840 unique vocab words\n"
     ]
    }
   ],
   "source": [
    "# all_test_l contains a unique list of words used in all of the texts\n",
    "print(f'{len(all_test_l)} unique vocab words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {'<PAD>': 0, '<UNK>': 1}\n",
    "idx2word = {0: '<PAD>', 1: '<UNK>'}\n",
    "\n",
    "for i in range(len(all_test_l)):\n",
    "    idx2word[i+2] = all_test_l[i]\n",
    "    word2idx[idx2word[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2idx_mapper(line):\n",
    "    idx_list = []\n",
    "    for word in line:\n",
    "        try:\n",
    "            idx_list.append(word2idx[word])\n",
    "        except:\n",
    "            idx_list.append(word2idx['<UNK>'])\n",
    "            pass\n",
    "    return idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized'] = df['line'].map(word2idx_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>genre</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[endless, green, hill, bisect, by, a, ribbon, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>endless green hill bisect by a ribbon of highw...</td>\n",
       "      <td>[16708, 12632, 13704, 8211, 4499, 1775, 15519,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[through, -PRON-, midafternoon, labor, flank, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>through -PRON- midafternoon labor flank the wo...</td>\n",
       "      <td>[13505, 2292, 10529, 20560, 10907, 18330, 1816...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[shudder, stall, big, blackfoot, indian, name,...</td>\n",
       "      <td>0</td>\n",
       "      <td>shudder stall big blackfoot indian name get ou...</td>\n",
       "      <td>[7998, 16303, 16322, 2219, 11611, 22654, 3336,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[near, the, center, of, the, work, gang, -PRON...</td>\n",
       "      <td>0</td>\n",
       "      <td>near the center of the work gang -PRON- smile ...</td>\n",
       "      <td>[2593, 18330, 5331, 20924, 18330, 18165, 7591,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[of, the, prisoner, be, who, look, up, grin, a...</td>\n",
       "      <td>0</td>\n",
       "      <td>of the prisoner be who look up grin at brady y...</td>\n",
       "      <td>[20924, 18330, 14303, 10666, 3311, 939, 4319, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                line  genre  \\\n",
       "0  [endless, green, hill, bisect, by, a, ribbon, ...      0   \n",
       "1  [through, -PRON-, midafternoon, labor, flank, ...      0   \n",
       "2  [shudder, stall, big, blackfoot, indian, name,...      0   \n",
       "3  [near, the, center, of, the, work, gang, -PRON...      0   \n",
       "4  [of, the, prisoner, be, who, look, up, grin, a...      0   \n",
       "\n",
       "                                                text  \\\n",
       "0  endless green hill bisect by a ribbon of highw...   \n",
       "1  through -PRON- midafternoon labor flank the wo...   \n",
       "2  shudder stall big blackfoot indian name get ou...   \n",
       "3  near the center of the work gang -PRON- smile ...   \n",
       "4  of the prisoner be who look up grin at brady y...   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [16708, 12632, 13704, 8211, 4499, 1775, 15519,...  \n",
       "1  [13505, 2292, 10529, 20560, 10907, 18330, 1816...  \n",
       "2  [7998, 16303, 16322, 2219, 11611, 22654, 3336,...  \n",
       "3  [2593, 18330, 5331, 20924, 18330, 18165, 7591,...  \n",
       "4  [20924, 18330, 14303, 10666, 3311, 939, 4319, ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['tokenized']\n",
    "y = df['genre']\n",
    "\n",
    "maxlen = 25\n",
    "\n",
    "X = pad_sequences(\n",
    "    X,\n",
    "    maxlen=maxlen,\n",
    "    padding='post'\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 25, 128)           2923520   \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 25, 64)            49408     \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 21, 64)            20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 21, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 5, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 96)                30816     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 3)                 291       \n",
      "=================================================================\n",
      "Total params: 3,024,835\n",
      "Trainable params: 3,024,707\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Train on 23320 samples, validate on 5830 samples\n",
      "Epoch 1/10\n",
      " - 5s - loss: 17.5406 - acc: 0.5278 - val_loss: 7.0090 - val_acc: 0.4407\n",
      "Epoch 2/10\n",
      " - 2s - loss: 3.0644 - acc: 0.8214 - val_loss: 1.6817 - val_acc: 0.6556\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.5241 - acc: 0.9114 - val_loss: 0.9210 - val_acc: 0.6738\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.2042 - acc: 0.9369 - val_loss: 0.8137 - val_acc: 0.6717\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.1434 - acc: 0.9549 - val_loss: 0.6804 - val_acc: 0.7261\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.1213 - acc: 0.9616 - val_loss: 0.5928 - val_acc: 0.7702\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.1087 - acc: 0.9665 - val_loss: 0.6218 - val_acc: 0.7336\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0794 - acc: 0.9769 - val_loss: 0.5569 - val_acc: 0.7633\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0679 - acc: 0.9808 - val_loss: 0.5779 - val_acc: 0.7700\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0710 - acc: 0.9797 - val_loss: 0.6387 - val_acc: 0.7777\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 128\n",
    "vocab_size = len(word2idx)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
    "\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "\n",
    "model.add(Conv1D(filters=64, kernel_size=5, activation='relu', kernel_regularizer=l2(0.5)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "\n",
    "\n",
    "#model.add(Conv1D(32, 4, activation='relu', kernel_regularizer=l2(0.5) ))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(96, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "#opt = Adam(lr = 0.1)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                   epochs=10,\n",
    "                   batch_size=512,\n",
    "                   verbose=2, \n",
    "                   validation_data = (X_test, y_test),\n",
    "                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "name": "loss",
         "type": "scatter",
         "uid": "2e0d6713-dcaf-4f92-9276-19e8bb73eab8",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
         ],
         "xaxis": "x2",
         "y": [
          17.540645142975638,
          3.064368190405504,
          0.5240553797620443,
          0.20418490997002833,
          0.14341901544334548,
          0.12127430544300308,
          0.10873339229341641,
          0.07937990713283087,
          0.0678561668095417,
          0.0709570697686071
         ],
         "yaxis": "y2"
        },
        {
         "name": "val_loss",
         "type": "scatter",
         "uid": "2f7f5363-8938-4191-9c27-51e901df4b19",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
         ],
         "xaxis": "x2",
         "y": [
          7.0090272273657455,
          1.6817177652290305,
          0.9209516441842499,
          0.8137488800092995,
          0.6803784062891023,
          0.5927673908694939,
          0.6217926416552496,
          0.5569476823046113,
          0.5778672492729043,
          0.6386782696889154
         ],
         "yaxis": "y2"
        },
        {
         "line": {
          "color": "rgb(0, 255, 255)"
         },
         "name": "acc",
         "type": "scatter",
         "uid": "ba1f2c00-472c-4dc1-bf34-d06bd79f6e3b",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
         ],
         "xaxis": "x",
         "y": [
          0.5277873067667718,
          0.8214408236343292,
          0.9114065177240257,
          0.936921097463441,
          0.954931389488037,
          0.9616209265502812,
          0.9665094341667397,
          0.9768867922074594,
          0.9807890223189039,
          0.9796740991378117
         ],
         "yaxis": "y"
        },
        {
         "line": {
          "color": "rgb(0, 255, 0)"
         },
         "name": "val_acc",
         "type": "scatter",
         "uid": "10a3fa21-5eb4-4baf-a51a-cfc792540eb1",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
         ],
         "xaxis": "x",
         "y": [
          0.44065180079401256,
          0.6555746147399497,
          0.673756431797152,
          0.6716981140867924,
          0.7260720412686186,
          0.7701543737439308,
          0.7336192102415893,
          0.7632933104222267,
          0.7699828464620927,
          0.7777015435552516
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Accuracy",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Loss",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "title": {
         "text": "Model Training"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ]
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ]
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"7b9327eb-2a3a-41cd-9542-f23378b4b261\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"7b9327eb-2a3a-41cd-9542-f23378b4b261\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '7b9327eb-2a3a-41cd-9542-f23378b4b261',\n",
       "                        [{\"name\": \"loss\", \"type\": \"scatter\", \"uid\": \"2e0d6713-dcaf-4f92-9276-19e8bb73eab8\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"xaxis\": \"x2\", \"y\": [17.540645142975638, 3.064368190405504, 0.5240553797620443, 0.20418490997002833, 0.14341901544334548, 0.12127430544300308, 0.10873339229341641, 0.07937990713283087, 0.0678561668095417, 0.0709570697686071], \"yaxis\": \"y2\"}, {\"name\": \"val_loss\", \"type\": \"scatter\", \"uid\": \"2f7f5363-8938-4191-9c27-51e901df4b19\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"xaxis\": \"x2\", \"y\": [7.0090272273657455, 1.6817177652290305, 0.9209516441842499, 0.8137488800092995, 0.6803784062891023, 0.5927673908694939, 0.6217926416552496, 0.5569476823046113, 0.5778672492729043, 0.6386782696889154], \"yaxis\": \"y2\"}, {\"line\": {\"color\": \"rgb(0, 255, 255)\"}, \"name\": \"acc\", \"type\": \"scatter\", \"uid\": \"ba1f2c00-472c-4dc1-bf34-d06bd79f6e3b\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"xaxis\": \"x\", \"y\": [0.5277873067667718, 0.8214408236343292, 0.9114065177240257, 0.936921097463441, 0.954931389488037, 0.9616209265502812, 0.9665094341667397, 0.9768867922074594, 0.9807890223189039, 0.9796740991378117], \"yaxis\": \"y\"}, {\"line\": {\"color\": \"rgb(0, 255, 0)\"}, \"name\": \"val_acc\", \"type\": \"scatter\", \"uid\": \"10a3fa21-5eb4-4baf-a51a-cfc792540eb1\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"xaxis\": \"x\", \"y\": [0.44065180079401256, 0.6555746147399497, 0.673756431797152, 0.6716981140867924, 0.7260720412686186, 0.7701543737439308, 0.7336192102415893, 0.7632933104222267, 0.7699828464620927, 0.7777015435552516], \"yaxis\": \"y\"}],\n",
       "                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Accuracy\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Loss\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"title\": {\"text\": \"Model Training\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0]}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0]}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}},\n",
       "                        {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('7b9327eb-2a3a-41cd-9542-f23378b4b261');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = pd.DataFrame(history.history)\n",
    "\n",
    "loss = go.Scatter(\n",
    "    x = history.index,\n",
    "    y = history.loss,\n",
    "    name = 'loss'\n",
    ")\n",
    "\n",
    "val_loss = go.Scatter(\n",
    "    x = history.index,\n",
    "    y = history.val_loss,\n",
    "    name = 'val_loss'\n",
    ")\n",
    "\n",
    "acc = go.Scatter(\n",
    "    x = history.index,\n",
    "    y = history.acc,\n",
    "    name = 'acc',\n",
    "    line = dict(color='rgb(0, 255, 255)')\n",
    ")\n",
    "\n",
    "val_acc = go.Scatter(\n",
    "    x = history.index,\n",
    "    y = history.val_acc,\n",
    "    name = 'val_acc',\n",
    "    line = dict(color='rgb(0, 255, 0)')\n",
    ")\n",
    "\n",
    "fig = tools.make_subplots(rows=1, cols=2, subplot_titles=('Accuracy', 'Loss'))\n",
    "\n",
    "fig.append_trace(loss, 1, 2)\n",
    "fig.append_trace(val_loss, 1, 2)\n",
    "\n",
    "fig.append_trace(acc, 1, 1)\n",
    "fig.append_trace(val_acc, 1, 1)\n",
    "\n",
    "fig['layout'].update(title='Model Training')\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.76      0.73      1372\n",
      "           1       0.72      0.88      0.79      1632\n",
      "           2       0.88      0.72      0.79      2826\n",
      "\n",
      "    accuracy                           0.78      5830\n",
      "   macro avg       0.77      0.79      0.77      5830\n",
      "weighted avg       0.79      0.78      0.78      5830\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "\n",
    "preds = []\n",
    "\n",
    "for p in pred:\n",
    "    result = np.where(p == np.amax(p))\n",
    "    preds.append(result[0][0])\n",
    "    \n",
    "print(classification_report(preds, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre(pred):\n",
    "    preds = []\n",
    "    for p in pred:\n",
    "        result = np.where(p == np.amax(pred))\n",
    "        preds.append(result[0][0])\n",
    "\n",
    "    return genre_dict[preds[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(line):\n",
    "    line = text_cleaner(line)\n",
    "    line = word2idx_mapper(line.split())\n",
    "    line = np.array(line).reshape(1, -1)\n",
    "    line = pad_sequences(line, maxlen=maxlen, padding='post')\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Comedy', 1: 'Horror', 2: 'Thriller'}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thriller'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '''Sometimes The Clothes At Gap Kids Are Too Flashy, So I'm Forced To Go To The American Girl Store \n",
    "        And Order Clothes For Large Colonial Dolls'''\n",
    "\n",
    "genre(\n",
    "    model.predict(\n",
    "        model_pipeline(text)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5830/5830 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 4s 661us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6386782437614061, 0.777701543718832]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fun Testing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "comedy_lines = [\n",
    "    'Sometimes The Clothes At Gap Kids Are Too Flashy, So I\\'m Forced To Go To The American Girl Store And Order Clothes For Large Colonial Dolls',   # Angela from The Office\n",
    "    'Just get a job? Why dont I strap on my job helmet, and squeeze down into a job cannon, AND FIRE OFF INTO JOBLAND, WHERE JOBS GROW ON JOBBIES?!!!',\n",
    "    'Yeah, well, we won\\'t get got though. We gonna get. See, Dee, people like us, we don\\'t get got. We go get.',\n",
    "    '[Holds up iPod] TOM PUT ALL MY RECORDS INTO THIS RECTANGLE. THE SONGS JUST PLAY ONE AFTER THE OTHER. THIS IS AN EXCELLENT RECTANGLE.',\n",
    "    'A bookstore is one of the only pieces of evidence we have that people are still thinking.',\n",
    "    'The IRS! Theyâ€™re like the Mafia, they can take anything they want!',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "comedy_lines = df[df['genre'] == 0]['text'].sample(10).values.tolist()\n",
    "horror_lines = df[df['genre'] == 1]['text'].sample(10).values.tolist()\n",
    "thriller_lines = df[df['genre'] == 2]['text'].sample(10).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------COMEDY------------\n",
      "GENRE: Comedy | LINE: be on the sofa make out when dana enter -PRON-... \n",
      "GENRE: Comedy | LINE: keep -PRON- there do whatever -PRON- have to but do... \n",
      "GENRE: Comedy | LINE: when -PRON- see -PRON- -PRON- will know when -PRON- see... \n",
      "GENRE: Comedy | LINE: from a point in the center of the screen a... \n",
      "GENRE: Comedy | LINE: the window and look out at the big jumbotron with... \n",
      "GENRE: Comedy | LINE: false one take -PRON- nose off well well -PRON- do... \n",
      "GENRE: Comedy | LINE: the building m tired so m go to sleep -PRON-... \n",
      "GENRE: Comedy | LINE: ganz be be chase cate fire at ganz ganz duck... \n",
      "GENRE: Comedy | LINE: dick who now who s be stupid the guy who... \n",
      "GENRE: Comedy | LINE: of reporter all shout question at once as babble be... \n",
      "------------------------\n",
      "\n",
      "------------HORROR------------\n",
      "GENRE: Horror | LINE: see -PRON- the classical music and freddy can be hear... \n",
      "GENRE: Thriller | LINE: customer but if -PRON- say this be an matter will... \n",
      "GENRE: Horror | LINE: killer gale rip the phone out of jennifer hand into... \n",
      "GENRE: Comedy | LINE: hand with ring on each finger scoop the wallet up... \n",
      "GENRE: Horror | LINE: coincide with the release of verdict and premiere all on... \n",
      "GENRE: Horror | LINE: turn toward peter slowly peter crawl under the table as... \n",
      "GENRE: Horror | LINE: of handrail that s still solid -PRON- see the catwalk... \n",
      "GENRE: Horror | LINE: crew that be here to demolish the house there be... \n",
      "GENRE: Horror | LINE: like -PRON- have be shove aside as -PRON- cautiously start... \n",
      "GENRE: Horror | LINE: dash -PRON- formerly macho sheriff primal instinct tell -PRON- only... \n",
      "------------------------\n",
      "\n",
      "------------THRILLER------------\n",
      "GENRE: Thriller | LINE: light flash the driver stop chuck reese get out and... \n",
      "GENRE: Thriller | LINE: fixated on a fade blue butterfly on the back of... \n",
      "GENRE: Thriller | LINE: actually chaotician hammond not even bother to cover -PRON- contempt... \n",
      "GENRE: Thriller | LINE: -PRON- peritoneal cavity be full of blood when -PRON- run... \n",
      "GENRE: Thriller | LINE: bill as -PRON- pass through bernzy start to follow but... \n",
      "GENRE: Thriller | LINE: can be 107 over the road bolt -PRON- say the... \n",
      "GENRE: Comedy | LINE: exist -PRON- have give -PRON- a name -PRON- find out... \n",
      "GENRE: Comedy | LINE: office standard issue desk standard issue lead jill through the... \n",
      "GENRE: Thriller | LINE: district supervisor on the door meyerling be short and bald... \n",
      "GENRE: Thriller | LINE: -PRON- do not know where to start what s wrong... \n"
     ]
    }
   ],
   "source": [
    "print('------------COMEDY------------')\n",
    "for line in comedy_lines:\n",
    "    g = genre(\n",
    "        model.predict(\n",
    "            model_pipeline(line)\n",
    "        )\n",
    "    )\n",
    "    sample_text = ' '.join(line.split()[0:10]) + '... '\n",
    "    print(f'GENRE: {g} | LINE: {sample_text}')\n",
    "    \n",
    "print('------------------------\\n')\n",
    "    \n",
    "print('------------HORROR------------')\n",
    "for line in horror_lines:\n",
    "    g = genre(\n",
    "        model.predict(\n",
    "            model_pipeline(line)\n",
    "        )\n",
    "    )\n",
    "    sample_text = ' '.join(line.split()[0:10]) + '... '\n",
    "    print(f'GENRE: {g} | LINE: {sample_text}')\n",
    "    \n",
    "print('------------------------\\n')\n",
    "\n",
    "print('------------THRILLER------------')\n",
    "for line in thriller_lines:\n",
    "    g = genre(\n",
    "        model.predict(\n",
    "            model_pipeline(line)\n",
    "        )\n",
    "    )\n",
    "    sample_text = ' '.join(line.split()[0:10]) + '... '\n",
    "    print(f'GENRE: {g} | LINE: {sample_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
